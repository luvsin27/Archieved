{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Objective</b>: To calculate the Floating Point Operations of a given precompiled deepspeech model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Assumptions:</b> \n",
    "1. I am not considering any hardware metrics like memory size, bandwith, clock speed, sockets, use of any specific ASIC/GPU\n",
    "2. As I was not provided with a 10 second audio sample,I will be making my own asumption in the regard \n",
    "3. the code presented has been taken from padlepadle/deepspeech but has been modified a bit to make it presentable and executable\n",
    "4. I am only considering english characters(size=1 byte per character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate floating point operations we will be counting [multiply-accumulate operations](https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why multiply-accumulate? \n",
    "Many of the computations in neural networks are dot products\n",
    "ie-\n",
    "y = w[0]*x[0] + w[1]*x[1] + w[2]*x[2] + ... + w[n-1]*x[n-1]\n",
    "w(vector) = weights and x(vector) = input y(scalar) = layer’s outputs. Typically a layer will have multiple outputs\n",
    "\n",
    "so for every 2 multiply operations there will be 1 addition.Therefore,generalising the macc for n dot product operations yields 'n' + 'n-1'  = 2n - 1 Flops\n",
    "\n",
    "\n",
    "In terms of FLOPS,  performs  FLOPS since there are n multiplications and n - 1 additions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Deepspeech Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from itertools import groupby\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from math import log\n",
    "import multiprocessing\n",
    "from collections import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.v2 as paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains DeepSpeech2 layers and networks.\"\"\"\n",
    "def conv_bn_layer(input, filter_size, num_channels_in, num_channels_out, stride,\n",
    "                  padding, act, index_range_data):\n",
    "    \"\"\"Convolution layer with batch normalization.\n",
    "    :param input: Input layer.\n",
    "    :type input: LayerOutput\n",
    "    :param filter_size: The x dimension of a filter kernel. Or input a tuple for\n",
    "                        two image dimension.\n",
    "    :type filter_size: int|tuple|list\n",
    "    :param num_channels_in: Number of input channels.\n",
    "    :type num_channels_in: int\n",
    "    :type num_channels_out: Number of output channels.\n",
    "    :type num_channels_in: out\n",
    "    :param padding: The x dimension of the padding. Or input a tuple for two\n",
    "                    image dimension.\n",
    "    :type padding: int|tuple|list\n",
    "    :param act: Activation type.\n",
    "    :type act: BaseActivation\n",
    "    :param index_range_data: Index range to indicate sub region.\n",
    "    :type index_range_data: LayerOutput\n",
    "    :return: Batch norm layer after convolution layer.\n",
    "    :rtype: LayerOutput\n",
    "    \"\"\"\n",
    "    conv_layer = paddle.layer.img_conv(\n",
    "        input=input,\n",
    "        filter_size=filter_size,\n",
    "        num_channels=num_channels_in,\n",
    "        num_filters=num_channels_out,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        act=paddle.activation.Linear(),\n",
    "        bias_attr=False)\n",
    "    batch_norm = paddle.layer.batch_norm(input=conv_layer, act=act)\n",
    "    # reset padding part to 0\n",
    "    scale_sub_region = paddle.layer.scale_sub_region(\n",
    "        batch_norm, index_range_data, value=0.0)\n",
    "    return scale_sub_region\n",
    "\n",
    "\n",
    "def bidirectional_simple_rnn_bn_layer(name, input, size, act, share_weights):\n",
    "    \"\"\"Bidirectonal simple rnn layer with sequence-wise batch normalization.\n",
    "    The batch normalization is only performed on input-state weights.\n",
    "    :param name: Name of the layer.\n",
    "    :type name: string\n",
    "    :param input: Input layer.\n",
    "    :type input: LayerOutput\n",
    "    :param size: Number of RNN cells.\n",
    "    :type size: int\n",
    "    :param act: Activation type.\n",
    "    :type act: BaseActivation\n",
    "    :param share_weights: Whether to share input-hidden weights between\n",
    "                          forward and backward directional RNNs.\n",
    "    :type share_weights: bool\n",
    "    :return: Bidirectional simple rnn layer.\n",
    "    :rtype: LayerOutput\n",
    "    \"\"\"\n",
    "    if share_weights:\n",
    "        # input-hidden weights shared between bi-direcitonal rnn.\n",
    "        input_proj = paddle.layer.fc(\n",
    "            input=input,\n",
    "            size=size,\n",
    "            act=paddle.activation.Linear(),\n",
    "            bias_attr=False)\n",
    "        # batch norm is only performed on input-state projection\n",
    "        input_proj_bn = paddle.layer.batch_norm(\n",
    "            input=input_proj, act=paddle.activation.Linear())\n",
    "        # forward and backward in time\n",
    "        forward_simple_rnn = paddle.layer.recurrent(\n",
    "            input=input_proj_bn, act=act, reverse=False)\n",
    "        backward_simple_rnn = paddle.layer.recurrent(\n",
    "            input=input_proj_bn, act=act, reverse=True)\n",
    "\n",
    "    else:\n",
    "        input_proj_forward = paddle.layer.fc(\n",
    "            input=input,\n",
    "            size=size,\n",
    "            act=paddle.activation.Linear(),\n",
    "            bias_attr=False)\n",
    "        input_proj_backward = paddle.layer.fc(\n",
    "            input=input,\n",
    "            size=size,\n",
    "            act=paddle.activation.Linear(),\n",
    "            bias_attr=False)\n",
    "        # batch norm is only performed on input-state projection\n",
    "        input_proj_bn_forward = paddle.layer.batch_norm(\n",
    "            input=input_proj_forward, act=paddle.activation.Linear())\n",
    "        input_proj_bn_backward = paddle.layer.batch_norm(\n",
    "            input=input_proj_backward, act=paddle.activation.Linear())\n",
    "        # forward and backward in time\n",
    "        forward_simple_rnn = paddle.layer.recurrent(\n",
    "            input=input_proj_bn_forward, act=act, reverse=False)\n",
    "        backward_simple_rnn = paddle.layer.recurrent(\n",
    "            input=input_proj_bn_backward, act=act, reverse=True)\n",
    "\n",
    "    return paddle.layer.concat(input=[forward_simple_rnn, backward_simple_rnn])\n",
    "\n",
    "\n",
    "def bidirectional_gru_bn_layer(name, input, size, act):\n",
    "    \"\"\"Bidirectonal gru layer with sequence-wise batch normalization.\n",
    "    The batch normalization is only performed on input-state weights.\n",
    "    :param name: Name of the layer.\n",
    "    :type name: string\n",
    "    :param input: Input layer.\n",
    "    :type input: LayerOutput\n",
    "    :param size: Number of RNN cells.\n",
    "    :type size: int\n",
    "    :param act: Activation type.\n",
    "    :type act: BaseActivation\n",
    "    :return: Bidirectional simple rnn layer.\n",
    "    :rtype: LayerOutput\n",
    "    \"\"\"\n",
    "    input_proj_forward = paddle.layer.fc(\n",
    "        input=input,\n",
    "        size=size * 3,\n",
    "        act=paddle.activation.Linear(),\n",
    "        bias_attr=False)\n",
    "    input_proj_backward = paddle.layer.fc(\n",
    "        input=input,\n",
    "        size=size * 3,\n",
    "        act=paddle.activation.Linear(),\n",
    "        bias_attr=False)\n",
    "    # batch norm is only performed on input-related projections\n",
    "    input_proj_bn_forward = paddle.layer.batch_norm(\n",
    "        input=input_proj_forward, act=paddle.activation.Linear())\n",
    "    input_proj_bn_backward = paddle.layer.batch_norm(\n",
    "        input=input_proj_backward, act=paddle.activation.Linear())\n",
    "    # forward and backward in time\n",
    "    forward_gru = paddle.layer.grumemory(\n",
    "        input=input_proj_bn_forward, act=act, reverse=False)\n",
    "    backward_gru = paddle.layer.grumemory(\n",
    "        input=input_proj_bn_backward, act=act, reverse=True)\n",
    "    return paddle.layer.concat(input=[forward_gru, backward_gru])\n",
    "\n",
    "\n",
    "def conv_group(input, num_stacks, index_range_datas):\n",
    "    \"\"\"Convolution group with stacked convolution layers.\n",
    "    :param input: Input layer.\n",
    "    :type input: LayerOutput\n",
    "    :param num_stacks: Number of stacked convolution layers.\n",
    "    :type num_stacks: int\n",
    "    :param index_range_datas: Index ranges for each convolution layer.\n",
    "    :type index_range_datas: tuple|list\n",
    "    :return: Output layer of the convolution group.\n",
    "    :rtype: LayerOutput\n",
    "    \"\"\"\n",
    "    conv = conv_bn_layer(\n",
    "        input=input,\n",
    "        filter_size=(11, 41),\n",
    "        num_channels_in=1,\n",
    "        num_channels_out=32,\n",
    "        stride=(3, 2),\n",
    "        padding=(5, 20),\n",
    "        act=paddle.activation.BRelu(),\n",
    "        index_range_data=index_range_datas[0])\n",
    "    for i in xrange(num_stacks - 1):\n",
    "        conv = conv_bn_layer(\n",
    "            input=conv,\n",
    "            filter_size=(11, 21),\n",
    "            num_channels_in=32,\n",
    "            num_channels_out=32,\n",
    "            stride=(1, 2),\n",
    "            padding=(5, 10),\n",
    "            act=paddle.activation.BRelu(),\n",
    "            index_range_data=index_range_datas[i + 1])\n",
    "    output_num_channels = 32\n",
    "    output_height = 160 // pow(2, num_stacks) + 1\n",
    "    return conv, output_num_channels, output_height\n",
    "\n",
    "\n",
    "def rnn_group(input, size, num_stacks, use_gru, share_rnn_weights):\n",
    "    \"\"\"RNN group with stacked bidirectional simple RNN layers.\n",
    "    :param input: Input layer.\n",
    "    :type input: LayerOutput\n",
    "    :param size: Number of RNN cells in each layer.\n",
    "    :type size: int\n",
    "    :param num_stacks: Number of stacked rnn layers.\n",
    "    :type num_stacks: int\n",
    "    :param use_gru: Use gru if set True. Use simple rnn if set False.\n",
    "    :type use_gru: bool\n",
    "    :param share_rnn_weights: Whether to share input-hidden weights between\n",
    "                              forward and backward directional RNNs.\n",
    "                              It is only available when use_gru=False.\n",
    "    :type share_weights: bool\n",
    "    :return: Output layer of the RNN group.\n",
    "    :rtype: LayerOutput\n",
    "    \"\"\"\n",
    "    output = input\n",
    "    for i in xrange(num_stacks):\n",
    "        if use_gru:\n",
    "            output = bidirectional_gru_bn_layer(\n",
    "                name=str(i),\n",
    "                input=output,\n",
    "                size=size,\n",
    "                act=paddle.activation.Relu())\n",
    "            # BRelu does not support hppl, need to add later. Use Relu instead.\n",
    "        else:\n",
    "            output = bidirectional_simple_rnn_bn_layer(\n",
    "                name=str(i),\n",
    "                input=output,\n",
    "                size=size,\n",
    "                act=paddle.activation.BRelu(),\n",
    "                share_weights=share_rnn_weights)\n",
    "    return output\n",
    "\n",
    "\n",
    "def deep_speech_v2_network(audio_data,\n",
    "                           text_data,\n",
    "                           seq_offset_data,\n",
    "                           seq_len_data,\n",
    "                           index_range_datas,\n",
    "                           dict_size,\n",
    "                           num_conv_layers=2,\n",
    "                           num_rnn_layers=3,\n",
    "                           rnn_size=256,\n",
    "                           use_gru=False,\n",
    "                           share_rnn_weights=True):\n",
    "    \"\"\"The DeepSpeech2 network structure.\n",
    "    :param audio_data: Audio spectrogram data layer.\n",
    "    :type audio_data: LayerOutput\n",
    "    :param text_data: Transcription text data layer.\n",
    "    :type text_data: LayerOutput\n",
    "    :param seq_offset_data: Sequence offset data layer.\n",
    "    :type seq_offset_data: LayerOutput\n",
    "    :param seq_len_data: Valid sequence length data layer.\n",
    "    :type seq_len_data: LayerOutput\n",
    "    :param index_range_datas: Index ranges data layers.\n",
    "    :type index_range_datas: tuple|list\n",
    "    :param dict_size: Dictionary size for tokenized transcription.\n",
    "    :type dict_size: int\n",
    "    :param num_conv_layers: Number of stacking convolution layers.\n",
    "    :type num_conv_layers: int\n",
    "    :param num_rnn_layers: Number of stacking RNN layers.\n",
    "    :type num_rnn_layers: int\n",
    "    :param rnn_size: RNN layer size (number of RNN cells).\n",
    "    :type rnn_size: int\n",
    "    :param use_gru: Use gru if set True. Use simple rnn if set False.\n",
    "    :type use_gru: bool\n",
    "    :param share_rnn_weights: Whether to share input-hidden weights between\n",
    "                              forward and backward direction RNNs.\n",
    "                              It is only available when use_gru=False.\n",
    "    :type share_weights: bool\n",
    "    :return: A tuple of an output unnormalized log probability layer (\n",
    "             before softmax) and a ctc cost layer.\n",
    "    :rtype: tuple of LayerOutput\n",
    "    \"\"\"\n",
    "    # convolution group\n",
    "    conv_group_output, conv_group_num_channels, conv_group_height = conv_group(\n",
    "        input=audio_data,\n",
    "        num_stacks=num_conv_layers,\n",
    "        index_range_datas=index_range_datas)\n",
    "    # convert data form convolution feature map to sequence of vectors\n",
    "    conv2seq = paddle.layer.block_expand(\n",
    "        input=conv_group_output,\n",
    "        num_channels=conv_group_num_channels,\n",
    "        stride_x=1,\n",
    "        stride_y=1,\n",
    "        block_x=1,\n",
    "        block_y=conv_group_height)\n",
    "    # remove padding part\n",
    "    remove_padding_data = paddle.layer.sub_seq(\n",
    "        input=conv2seq,\n",
    "        offsets=seq_offset_data,\n",
    "        sizes=seq_len_data,\n",
    "        act=paddle.activation.Linear(),\n",
    "        bias_attr=False)\n",
    "    # rnn group\n",
    "    rnn_group_output = rnn_group(\n",
    "        input=remove_padding_data,\n",
    "        size=rnn_size,\n",
    "        num_stacks=num_rnn_layers,\n",
    "        use_gru=use_gru,\n",
    "        share_rnn_weights=share_rnn_weights)\n",
    "    fc = paddle.layer.fc(\n",
    "        input=rnn_group_output,\n",
    "        size=dict_size + 1,\n",
    "        act=paddle.activation.Linear(),\n",
    "        bias_attr=True)\n",
    "    # probability distribution with softmax\n",
    "    log_probs = paddle.layer.mixed(\n",
    "        input=paddle.layer.identity_projection(input=fc),\n",
    "        act=paddle.activation.Softmax())\n",
    "    # ctc cost\n",
    "    ctc_loss = paddle.layer.warp_ctc(\n",
    "        input=fc,\n",
    "        label=text_data,\n",
    "        size=dict_size + 1,\n",
    "        blank=dict_size,\n",
    "        norm_by_times=True)\n",
    "    return log_probs, ctc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flop Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets break the network into basic units and try to evaluate each part of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.fc(\n",
    "            input=input,\n",
    "            size=size,\n",
    "            act=paddle.activation.Linear(),\n",
    "            bias_attr=False)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the fully-connected layer above, all the inputs are connected to all the output and output at each layer is given by \n",
    "y = matmul(x, W) + b\n",
    "\n",
    "consider __I__ to be the __input values__ and __J__ to be the __ouput values__ then dimensionsal represention is given by \n",
    "\n",
    "y(J)=x(I)*W(I,J)+b(J) \n",
    "\n",
    "now the multiply-aaumalate operations for the above code is I×J ((2I-1)×J Flops) as discussed above  \n",
    "\n",
    "The bias b doesn’t really affect the number of MACCs as the dot product has one less addition than multiplication, so adding this bias value simply gets absorbed in that final multiply-accumulate.\n",
    "\n",
    "Note: In case of batch size B, the resulting becomes (2I-1)×J×B;also,In the first code linear activation does not do anything \n",
    "\n",
    "let's define a fuction below to evaluate this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLops_fc_layer(m, x, y):\n",
    "    # per output element\n",
    "    Multipication_Operations = m.input\n",
    "    Addition_Operation = m.input - 1\n",
    "    Bias_Operations = 1 if m.bias is not None else 0\n",
    "    Number_Of_Elements = y.numel()\n",
    "    Total_Operations = (Multipication_Operations + Addition_Operation + Bias_Operations) * Number_Of_Elements\n",
    "\n",
    "    m.Total_FLops.append(Total_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.img_conv(input=input, filter_size=filter_size, num_channels=num_channels_in, num_filters=num_channels_out, stride=stride, padding=padding, act=paddle.activation.Linear(), bias_attr=False)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as per the [documentaion](https://www.paddlepaddle.org.cn/documentation/api/en/0.10.0/v2/config/layer.html#img-conv)\n",
    "here convolutional layer currently supports rectangular kernels. \n",
    "\n",
    "Consider the convolutional layer with three-dimensional feature maps of size H(height) × W(width) × C(channels) and kernel size Kx(kernel width) × Ky(kernel height)\n",
    "\n",
    "Although, the convolution layer consists of dilation factors,strides,padding,etc that should not be ignored,the dimensions of the output layer's feature map(Hout × Wout) have it accounted for.Also,we take the dot product of the weights and a Kx × Ky window of input values across all input channels Cin and because the layer has Cout different and repeat this Cout times to create all the output channels (bias and the activation function(linear) is ignored here).\n",
    "\n",
    "For the above conv layer the number of Multiply Accumalte Operations are:\n",
    "Cin × Kx × Ky × Hout × Wout × Cout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLops_img_conv(m, x, y):\n",
    "    x = x[0]\n",
    "\n",
    "    Cin = m.num_channels\n",
    "    Cout = m.num_filters\n",
    "    Kx, Ky = m.filter_size\n",
    "\n",
    "    H_out = y.size(2)\n",
    "    W_out = y.size(3)\n",
    "\n",
    "    # Flops per output element\n",
    "    Filter_Multipication_Operations = Kx * Ky * Cin\n",
    "    Filter_Addition_Operations = Kx * Ky * Cin - 1\n",
    "    Filter_Operations =  Filter_Multipication_Operations+Filter_Addition_Operations\n",
    "    Bias_Operations = 1 if m.bias is not None else 0\n",
    "    Operations_Per_Element = Filter_Operations + Bias_Operations\n",
    "\n",
    "    # total Flops\n",
    "    Number_Of_Output_Elements = y.numel()\n",
    "    Output_Elements = Number_of_Output_Elements * W_out * H_out * Cout\n",
    "    Total_Operations = output_elements * ops_per_element * Cin\n",
    "    m.Total_FLops.append(Total_operations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.batch_norm(input=conv_layer, act=act)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch normalization takes the output of a layer and applies the following formula to every single output value:\n",
    "\n",
    "z = gamma * (y - mean) / sqrt(variance + epsilon) + beta\n",
    "y is an element in the output from the previous layer.\n",
    "\n",
    "Since we are only concerned MACC,we can count this as 4 operations being performed on different number of elements present in the input of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLops_bn_layer(m, x, y):\n",
    "    x = x[0]\n",
    "\n",
    "    Number_Of_Input_Elements = x.numel()\n",
    "    # subtract, divide, gamma, beta\n",
    "    Total_operations = 4 * Number_Of_Input_Elements\n",
    "\n",
    "    m.Total_FLops.append(Total_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.recurrent(input=input_proj_bn, act=act, reverse=False)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the documentaion\n",
    "\n",
    "It is just a fully connect layer through both time and neural network.\n",
    "\n",
    "For each sequence [start, end] it performs the following computation:\n",
    "outi=act(ini)  for $i=startout(i)=act(ini+outi−1∗W)$  for $start<i<=end$\n",
    "\n",
    "If reversed is true, the order is reversed:\n",
    "outi=act(ini)  for $i=endout(i)=act(ini+outi+1∗W)$  for $start<=i<end$\n",
    "\n",
    "i.e RNN could be counted as a fully connected layer,as it is difficult to know how many time steps it will take for the neural network to process the input we can consider it has simmilar flops to paddle.layer.fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.grumemory(input=input_proj_bn_forward, act=act, reverse=False)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as per the doumentaion this function doesn't perform the multiplication operations $W_{r}x_{t}$, $W_{z}x_{t}$ and $W x_t$.Now assuming it only performs $U_{z}h_{t-1}$,$U_{r}h_{t-1}$ and $r_{t} \\odot h_{t-1}$ (depending on whether reverse is true or not) and an additonal '+' function ,ie we can consider \n",
    "                         \n",
    "                         'dot product' + 'addition' = n + n-1 + 1\n",
    "                                                    = 2n Flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLops_Gru_memory(m, x, y):\n",
    "    # per output element\n",
    "    Multipication_Operations = m.input\n",
    "    Addition_Operation = m.input - 1\n",
    "    Bias_Operations = 1 if m.bias is not None else 0\n",
    "    Number_Of_Elements = y.numel()\n",
    "    Total_Operations = (Multipication_Operations + Addition_Operation + Bias_Operations) * Number_Of_Elements\n",
    "\n",
    "    m.Total_FLops.append(Total_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation functions mentioned here are RELU and BRELU apart from  linear which are genrally in the form:\n",
    "\n",
    "y = max(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLops_relu(m, x, y):\n",
    "    x = x[0]\n",
    "\n",
    "    Number_Of_Input_Elements = x.numel()\n",
    "    Total_Operations = Number_Of_Input_Elements\n",
    "\n",
    "    m.Total_FLops.append(Total_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.mixed()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mixed layer will add all inputs together, then activate. Hence it performs only adds layes of inputs together and doesn't perform any multiply accumulate operations,we can count it as zero operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Zero_FLops(m, x, y):\n",
    "    m.Total_FLops.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.block_expand()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converts data form convolution feature map to sequence of vectors.therefore this performs only zero MACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.layer.identity_projection()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function increments the ith element in row of output by ith elment times the input or (input+offset) if offset is present.therefore,total number of addition operations would be the sum total of all inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLops_identity_projection(m, x, y):\n",
    "    x = y.offset + x\n",
    "    Total_Operations = x.sum()\n",
    "    m.Total_FLops.append(Total_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*paddle.activation.Softmax()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax is calculated as follows $p_{k} = \\dfrac{e^{f_{k}}}{\\sum_{j} e^{f_{j}}}$.This roughly equates to 3 operations done on number of features (addition,division and exponential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Flops_softmax(m, x, y):\n",
    "    x = x[0]\n",
    "\n",
    "    batch_size, nfeatures = x.size()\n",
    "\n",
    "    Total_Exponential = nfeatures\n",
    "    Total_Addition = nfeatures - 1\n",
    "    Total_Divisons = nfeatures\n",
    "    Total_operations = batch_size * (total_exp + total_add + total_div)\n",
    "\n",
    "    m.Total_FLops.append(Total_operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have developed a method to count the number of flops for individual layers,lets now define a function to calculate the flops of the whole network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We are not considering CTC loss as it mostly involves memory operations rather than Multiply-Accumalate operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating FLOPS of Layer\n",
    "Registered_Layers = {\n",
    "    paddle.layer.fc: FLops_fc_layer,\n",
    "    paddle.layer.recurrent: FLops_fc_layer,\n",
    "    \n",
    "    paddle.layer.img_conv: FLops_img_conv,\n",
    "\n",
    "    paddle.layer.batch_norm: FLops_bn_layer,\n",
    "\n",
    "    paddle.layer.grumemory: FLops_Gru_memory,\n",
    "    \n",
    "    paddle.activation.relu: FLops_relu,\n",
    "    paddle.activation.brelu: FLops_relu,\n",
    "\n",
    "    paddle.layer.mixed: Zero_FLops,\n",
    "    paddle.layer.block_expand: Zero_FLops,\n",
    "    paddle.layer.identity_projection: FLops_identity_projection,\n",
    "    \n",
    "    paddle.activation.Softmax: Flops_softmax,\n",
    "}\n",
    "\n",
    "\n",
    "def Interpret_Model(model, inputs, verbose=True):\n",
    "    \n",
    "    collected_operations = []\n",
    "\n",
    "    def add_layers(m):\n",
    "        if len(list(m.children())) > 0:\n",
    "            return\n",
    "\n",
    "        m_type = m.type\n",
    "        fn = None\n",
    "        fn = Registered_Layers[m_type]\n",
    "\n",
    "        if fn is None:\n",
    "            if verbose:\n",
    "                print(\"Method has not implemented counting method for \", m)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Registered FLOP counter for %s\" % str(m))\n",
    "        operations = m.add(fn)  # write a function to build the model.\n",
    "        collected_operations.append(operations)\n",
    "\n",
    "    training = model.training\n",
    "\n",
    "    model.eval()\n",
    "    model.apply(add_layers)\n",
    "\n",
    "    Total_Flops = 0\n",
    "    for m in model.modules():\n",
    "        if len(list(m.children())) > 0:  # skip for non-leaf module\n",
    "            continue\n",
    "        total_ops += m.Total_Flops\n",
    "        \n",
    "    Total_Flops = Total_Flops.item()\n",
    "\n",
    "    # reset model to original status\n",
    "    model.train(training)\n",
    "    for operations in collected_operations:\n",
    "        operations.remove()\n",
    "\n",
    "    # remove temporal buffers\n",
    "    for n, m in model.Params():\n",
    "        if len(list(m.children())) > 0:\n",
    "            continue\n",
    "        if \"Total_Flops\" in m._buffers:\n",
    "            m._buffers.pop(\"Total_Flops\")\n",
    "\n",
    "    return Total_Flops\n",
    "\n",
    "# function to print summary\n",
    "def print_summary(nums, format=\"%.2f\"):\n",
    "    if not isinstance(nums, Iterable):\n",
    "        nums = [nums]\n",
    "    summary = []\n",
    "\n",
    "    for num in nums:\n",
    "        if num > 1e12:\n",
    "            summary.append(format % (num / 1e12) + \"T\")\n",
    "        elif num > 1e9:\n",
    "            summary.append(format % (num / 1e9) + \"G\")\n",
    "        elif num > 1e6:\n",
    "            summary.append(format % (num / 1e6) + \"M\")\n",
    "        elif num > 1e3:\n",
    "            summary.append(format % (num / 1e3) + \"K\")\n",
    "        else:\n",
    "            summary.append(format % num + \"B\")\n",
    "\n",
    "    summary = summary[0] if len(summary) == 1 else (*summary, )\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTC for Deepspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_greedy_decoder(probs_seq, vocabulary):\n",
    "    \"\"\"CTC greedy (best path) decoder.\n",
    "    Path consisting of the most probable tokens are further post-processed to\n",
    "    remove consecutive repetitions and all blanks.\n",
    "    :param probs_seq: 2-D list of probabilities over the vocabulary for each\n",
    "                      character. Each element is a list of float probabilities\n",
    "                      for one character.\n",
    "    :type probs_seq: list\n",
    "    :param vocabulary: Vocabulary list.\n",
    "    :type vocabulary: list\n",
    "    :return: Decoding result string.\n",
    "    :rtype: baseline\n",
    "    \"\"\"\n",
    "    # dimension verification\n",
    "    for probs in probs_seq:\n",
    "        if not len(probs) == len(vocabulary) + 1:\n",
    "            raise ValueError(\"probs_seq dimension mismatchedd with vocabulary\")\n",
    "    # argmax to get the best index for each time step\n",
    "    max_index_list = list(np.array(probs_seq).argmax(axis=1))\n",
    "    # remove consecutive duplicate indexes\n",
    "    index_list = [index_group[0] for index_group in groupby(max_index_list)]\n",
    "    # remove blank indexes\n",
    "    blank_index = len(vocabulary)\n",
    "    index_list = [index for index in index_list if index != blank_index]\n",
    "    # convert index list to string\n",
    "    return ''.join([vocabulary[index] for index in index_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_beam_search_decoder(probs_seq,\n",
    "                            beam_size,\n",
    "                            vocabulary,\n",
    "                            cutoff_prob=1.0,\n",
    "                            cutoff_top_n=40,\n",
    "                            ext_scoring_func=None,\n",
    "                            nproc=False):\n",
    "    \"\"\"CTC Beam search decoder.\n",
    "    It utilizes beam search to approximately select top best decoding\n",
    "    labels and returning results in the descending order.\n",
    "    The implementation is based on Prefix Beam Search\n",
    "    (https://arxiv.org/abs/1408.2873), and the unclear part is\n",
    "    redesigned. Two important modifications: 1) in the iterative computation\n",
    "    of probabilities, the assignment operation is changed to accumulation for\n",
    "    one prefix may comes from different paths; 2) the if condition \"if l^+ not\n",
    "    in A_prev then\" after probabilities' computation is deprecated for it is\n",
    "    hard to understand and seems unnecessary.\n",
    "    :param probs_seq: 2-D list of probability distributions over each time\n",
    "                      step, with each element being a list of normalized\n",
    "                      probabilities over vocabulary and blank.\n",
    "    :type probs_seq: 2-D list\n",
    "    :param beam_size: Width for beam search.\n",
    "    :type beam_size: int\n",
    "    :param vocabulary: Vocabulary list.\n",
    "    :type vocabulary: list\n",
    "    :param cutoff_prob: Cutoff probability in pruning,\n",
    "                        default 1.0, no pruning.\n",
    "    :type cutoff_prob: float\n",
    "    :param ext_scoring_func: External scoring function for\n",
    "                            partially decoded sentence, e.g. word count\n",
    "                            or language model.\n",
    "    :type external_scoring_func: callable\n",
    "    :param nproc: Whether the decoder used in multiprocesses.\n",
    "    :type nproc: bool\n",
    "    :return: List of tuples of log probability and sentence as decoding\n",
    "             results, in descending order of the probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    # dimension check\n",
    "    for prob_list in probs_seq:\n",
    "        if not len(prob_list) == len(vocabulary) + 1:\n",
    "            raise ValueError(\"The shape of prob_seq does not match with the \"\n",
    "                             \"shape of the vocabulary.\")\n",
    "\n",
    "    # blank_id assign\n",
    "    blank_id = len(vocabulary)\n",
    "\n",
    "    # If the decoder called in the multiprocesses, then use the global scorer\n",
    "    # instantiated in ctc_beam_search_decoder_batch().\n",
    "    if nproc is True:\n",
    "        global ext_nproc_scorer\n",
    "        ext_scoring_func = ext_nproc_scorer\n",
    "\n",
    "    ## initialize\n",
    "    # prefix_set_prev: the set containing selected prefixes\n",
    "    # probs_b_prev: prefixes' probability ending with blank in previous step\n",
    "    # probs_nb_prev: prefixes' probability ending with non-blank in previous step\n",
    "    prefix_set_prev = {'\\t': 1.0}\n",
    "    probs_b_prev, probs_nb_prev = {'\\t': 1.0}, {'\\t': 0.0}\n",
    "\n",
    "    ## extend prefix in loop\n",
    "    for time_step in xrange(len(probs_seq)):\n",
    "        # prefix_set_next: the set containing candidate prefixes\n",
    "        # probs_b_cur: prefixes' probability ending with blank in current step\n",
    "        # probs_nb_cur: prefixes' probability ending with non-blank in current step\n",
    "        prefix_set_next, probs_b_cur, probs_nb_cur = {}, {}, {}\n",
    "\n",
    "        prob_idx = list(enumerate(probs_seq[time_step]))\n",
    "        cutoff_len = len(prob_idx)\n",
    "        #If pruning is enabled\n",
    "        if cutoff_prob < 1.0 or cutoff_top_n < cutoff_len:\n",
    "            prob_idx = sorted(prob_idx, key=lambda asd: asd[1], reverse=True)\n",
    "            cutoff_len, cum_prob = 0, 0.0\n",
    "            for i in xrange(len(prob_idx)):\n",
    "                cum_prob += prob_idx[i][1]\n",
    "                cutoff_len += 1\n",
    "                if cum_prob >= cutoff_prob:\n",
    "                    break\n",
    "            cutoff_len = min(cutoff_len, cutoff_top_n)\n",
    "            prob_idx = prob_idx[0:cutoff_len]\n",
    "\n",
    "        for l in prefix_set_prev:\n",
    "            if not prefix_set_next.has_key(l):\n",
    "                probs_b_cur[l], probs_nb_cur[l] = 0.0, 0.0\n",
    "\n",
    "            # extend prefix by travering prob_idx\n",
    "            for index in xrange(cutoff_len):\n",
    "                c, prob_c = prob_idx[index][0], prob_idx[index][1]\n",
    "\n",
    "                if c == blank_id:\n",
    "                    probs_b_cur[l] += prob_c * (\n",
    "                        probs_b_prev[l] + probs_nb_prev[l])\n",
    "                else:\n",
    "                    last_char = l[-1]\n",
    "                    new_char = vocabulary[c]\n",
    "                    l_plus = l + new_char\n",
    "                    if not prefix_set_next.has_key(l_plus):\n",
    "                        probs_b_cur[l_plus], probs_nb_cur[l_plus] = 0.0, 0.0\n",
    "\n",
    "                    if new_char == last_char:\n",
    "                        probs_nb_cur[l_plus] += prob_c * probs_b_prev[l]\n",
    "                        probs_nb_cur[l] += prob_c * probs_nb_prev[l]\n",
    "                    elif new_char == ' ':\n",
    "                        if (ext_scoring_func is None) or (len(l) == 1):\n",
    "                            score = 1.0\n",
    "                        else:\n",
    "                            prefix = l[1:]\n",
    "                            score = ext_scoring_func(prefix)\n",
    "                        probs_nb_cur[l_plus] += score * prob_c * (\n",
    "                            probs_b_prev[l] + probs_nb_prev[l])\n",
    "                    else:\n",
    "                        probs_nb_cur[l_plus] += prob_c * (\n",
    "                            probs_b_prev[l] + probs_nb_prev[l])\n",
    "                    # add l_plus into prefix_set_next\n",
    "                    prefix_set_next[l_plus] = probs_nb_cur[\n",
    "                        l_plus] + probs_b_cur[l_plus]\n",
    "            # add l into prefix_set_next\n",
    "            prefix_set_next[l] = probs_b_cur[l] + probs_nb_cur[l]\n",
    "        # update probs\n",
    "        probs_b_prev, probs_nb_prev = probs_b_cur, probs_nb_cur\n",
    "\n",
    "        ## store top beam_size prefixes\n",
    "        prefix_set_prev = sorted(\n",
    "            prefix_set_next.iteritems(), key=lambda asd: asd[1], reverse=True)\n",
    "        if beam_size < len(prefix_set_prev):\n",
    "            prefix_set_prev = prefix_set_prev[:beam_size]\n",
    "        prefix_set_prev = dict(prefix_set_prev)\n",
    "\n",
    "    beam_result = []\n",
    "    for seq, prob in prefix_set_prev.items():\n",
    "        if prob > 0.0 and len(seq) > 1:\n",
    "            result = seq[1:]\n",
    "            # score last word by external scorer\n",
    "            if (ext_scoring_func is not None) and (result[-1] != ' '):\n",
    "                prob = prob * ext_scoring_func(result)\n",
    "            log_prob = log(prob)\n",
    "            beam_result.append((log_prob, result))\n",
    "        else:\n",
    "            beam_result.append((float('-inf'), ''))\n",
    "\n",
    "    ## output top beam_size decoding results\n",
    "    beam_result = sorted(beam_result, key=lambda asd: asd[0], reverse=True)\n",
    "    return beam_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_beam_search_decoder_batch(probs_split,\n",
    "                                  beam_size,\n",
    "                                  vocabulary,\n",
    "                                  num_processes,\n",
    "                                  cutoff_prob=1.0,\n",
    "                                  cutoff_top_n=40,\n",
    "                                  ext_scoring_func=None):\n",
    "    \"\"\"CTC beam search decoder using multiple processes.\n",
    "    :param probs_seq: 3-D list with each element as an instance of 2-D list\n",
    "                      of probabilities used by ctc_beam_search_decoder().\n",
    "    :type probs_seq: 3-D list\n",
    "    :param beam_size: Width for beam search.\n",
    "    :type beam_size: int\n",
    "    :param vocabulary: Vocabulary list.\n",
    "    :type vocabulary: list\n",
    "    :param num_processes: Number of parallel processes.\n",
    "    :type num_processes: int\n",
    "    :param cutoff_prob: Cutoff probability in pruning,\n",
    "                        default 1.0, no pruning.\n",
    "    :type cutoff_prob: float\n",
    "    :param num_processes: Number of parallel processes.\n",
    "    :type num_processes: int\n",
    "    :param ext_scoring_func: External scoring function for\n",
    "                            partially decoded sentence, e.g. word count\n",
    "                            or language model.\n",
    "    :type external_scoring_function: callable\n",
    "    :return: List of tuples of log probability and sentence as decoding\n",
    "             results, in descending order of the probability.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if not num_processes > 0:\n",
    "        raise ValueError(\"Number of processes must be positive!\")\n",
    "\n",
    "    # use global variable to pass the externnal scorer to beam search decoder\n",
    "    global ext_nproc_scorer\n",
    "    ext_nproc_scorer = ext_scoring_func\n",
    "    nproc = True\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "    results = []\n",
    "    for i, probs_list in enumerate(probs_split):\n",
    "        args = (probs_list, beam_size, vocabulary, cutoff_prob, cutoff_top_n,\n",
    "                None, nproc)\n",
    "        results.append(pool.apply_async(ctc_beam_search_decoder, args))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    beam_search_results = [result.get() for result in results]\n",
    "    return beam_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"External Scorer for Beam Search Decoder.\"\"\"\n",
    "class Scorer(object):\n",
    "    \"\"\"External scorer to evaluate a prefix or whole sentence in\n",
    "       beam search decoding, including the score from n-gram language\n",
    "       model and word count.\n",
    "    :param alpha: Parameter associated with language model. Don't use\n",
    "                  language model when alpha = 0.\n",
    "    :type alpha: float\n",
    "    :param beta: Parameter associated with word count. Don't use word\n",
    "                count when beta = 0.\n",
    "    :type beta: float\n",
    "    :model_path: Path to load language model.\n",
    "    :type model_path: basestring\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha, beta, model_path):\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "        if not os.path.isfile(model_path):\n",
    "            raise IOError(\"Invaid language model path: %s\" % model_path)\n",
    "        self._language_model = kenlm.LanguageModel(model_path)\n",
    "\n",
    "    # n-gram language model scoring\n",
    "    def _language_model_score(self, sentence):\n",
    "        #log10 prob of last word\n",
    "        log_cond_prob = list(\n",
    "            self._language_model.full_scores(sentence, eos=False))[-1][0]\n",
    "        return np.power(10, log_cond_prob)\n",
    "\n",
    "    # word insertion term\n",
    "    def _word_count(self, sentence):\n",
    "        words = sentence.strip().split(' ')\n",
    "        return len(words)\n",
    "\n",
    "    # reset alpha and beta\n",
    "    def reset_params(self, alpha, beta):\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "\n",
    "    # execute evaluation\n",
    "    def __call__(self, sentence, log=False):\n",
    "        \"\"\"Evaluation function, gathering all the different scores\n",
    "        and return the final one.\n",
    "        :param sentence: The input sentence for evalutation\n",
    "        :type sentence: basestring\n",
    "        :param log: Whether return the score in log representation.\n",
    "        :type log: bool\n",
    "        :return: Evaluation score, in the decimal or log.\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        lm = self._language_model_score(sentence)\n",
    "        word_cnt = self._word_count(sentence)\n",
    "        if log == False:\n",
    "            score = np.power(lm, self._alpha) * np.power(word_cnt, self._beta)\n",
    "        else:\n",
    "            score = self._alpha * np.log(lm) + self._beta * np.log(word_cnt)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepspeech Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import gzip\n",
    "import copy\n",
    "import inspect\n",
    "from distutils.dir_util import mkpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains DeepSpeech2 model.\"\"\"\n",
    "logging.basicConfig(\n",
    "    format='[%(levelname)s %(asctime)s %(filename)s:%(lineno)d] %(message)s')\n",
    "\n",
    "\n",
    "class DeepSpeech2Model(object):\n",
    "    \"\"\"DeepSpeech2Model class.\n",
    "    :param vocab_size: Decoding vocabulary size.\n",
    "    :type vocab_size: int\n",
    "    :param num_conv_layers: Number of stacking convolution layers.\n",
    "    :type num_conv_layers: int\n",
    "    :param num_rnn_layers: Number of stacking RNN layers.\n",
    "    :type num_rnn_layers: int\n",
    "    :param rnn_layer_size: RNN layer size (number of RNN cells).\n",
    "    :type rnn_layer_size: int\n",
    "    :param pretrained_model_path: Pretrained model path. If None, will train\n",
    "                                  from stratch.\n",
    "    :type pretrained_model_path: basestring|None\n",
    "    :param share_rnn_weights: Whether to share input-hidden weights between\n",
    "                              forward and backward directional RNNs.Notice that\n",
    "                              for GRU, weight sharing is not supported.\n",
    "    :type share_rnn_weights: bool\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, num_conv_layers, num_rnn_layers,\n",
    "                 rnn_layer_size, use_gru, pretrained_model_path,\n",
    "                 share_rnn_weights):\n",
    "        self._create_network(vocab_size, num_conv_layers, num_rnn_layers,\n",
    "                             rnn_layer_size, use_gru, share_rnn_weights)\n",
    "        self._create_parameters(pretrained_model_path)\n",
    "        self._inferer = None\n",
    "        self._loss_inferer = None\n",
    "        self._ext_scorer = None\n",
    "        self._num_conv_layers = num_conv_layers\n",
    "        self.logger = logging.getLogger(\"\")\n",
    "        self.logger.setLevel(level=logging.INFO)\n",
    "\n",
    "    def train(self,\n",
    "              train_batch_reader,\n",
    "              dev_batch_reader,\n",
    "              feeding_dict,\n",
    "              learning_rate,\n",
    "              gradient_clipping,\n",
    "              num_passes,\n",
    "              output_model_dir,\n",
    "              is_local=True,\n",
    "              num_iterations_print=100,\n",
    "              test_off=False):\n",
    "        \"\"\"Train the model.\n",
    "        :param train_batch_reader: Train data reader.\n",
    "        :type train_batch_reader: callable\n",
    "        :param dev_batch_reader: Validation data reader.\n",
    "        :type dev_batch_reader: callable\n",
    "        :param feeding_dict: Feeding is a map of field name and tuple index\n",
    "                             of the data that reader returns.\n",
    "        :type feeding_dict: dict|list\n",
    "        :param learning_rate: Learning rate for ADAM optimizer.\n",
    "        :type learning_rate: float\n",
    "        :param gradient_clipping: Gradient clipping threshold.\n",
    "        :type gradient_clipping: float\n",
    "        :param num_passes: Number of training epochs.\n",
    "        :type num_passes: int\n",
    "        :param num_iterations_print: Number of training iterations for printing\n",
    "                                     a training loss.\n",
    "        :type rnn_iteratons_print: int\n",
    "        :param is_local: Set to False if running with pserver with multi-nodes.\n",
    "        :type is_local: bool\n",
    "        :param output_model_dir: Directory for saving the model (every pass).\n",
    "        :type output_model_dir: basestring\n",
    "        :param test_off: Turn off testing.\n",
    "        :type test_off: bool\n",
    "        \"\"\"\n",
    "        # prepare model output directory\n",
    "        if not os.path.exists(output_model_dir):\n",
    "            mkpath(output_model_dir)\n",
    "\n",
    "        # adapt the feeding dict and reader according to the network\n",
    "        adapted_feeding_dict = self._adapt_feeding_dict(feeding_dict)\n",
    "        adapted_train_batch_reader = self._adapt_data(train_batch_reader)\n",
    "        adapted_dev_batch_reader = self._adapt_data(dev_batch_reader)\n",
    "\n",
    "        # prepare optimizer and trainer\n",
    "        optimizer = paddle.optimizer.Adam(\n",
    "            learning_rate=learning_rate,\n",
    "            gradient_clipping_threshold=gradient_clipping)\n",
    "        trainer = paddle.trainer.SGD(\n",
    "            cost=self._loss,\n",
    "            parameters=self._parameters,\n",
    "            update_equation=optimizer,\n",
    "            is_local=is_local)\n",
    "\n",
    "        # create event handler\n",
    "        def event_handler(event):\n",
    "            global start_time, cost_sum, cost_counter\n",
    "            if isinstance(event, paddle.event.EndIteration):\n",
    "                cost_sum += event.cost\n",
    "                cost_counter += 1\n",
    "                if (event.batch_id + 1) % num_iterations_print == 0:\n",
    "                    output_model_path = os.path.join(output_model_dir,\n",
    "                                                     \"params.latest.tar.gz\")\n",
    "                    with gzip.open(output_model_path, 'w') as f:\n",
    "                        trainer.save_parameter_to_tar(f)\n",
    "                    print(\"\\nPass: %d, Batch: %d, TrainCost: %f\" %\n",
    "                          (event.pass_id, event.batch_id + 1,\n",
    "                           cost_sum / cost_counter))\n",
    "                    cost_sum, cost_counter = 0.0, 0\n",
    "                else:\n",
    "                    sys.stdout.write('.')\n",
    "                    sys.stdout.flush()\n",
    "            if isinstance(event, paddle.event.BeginPass):\n",
    "                start_time = time.time()\n",
    "                cost_sum, cost_counter = 0.0, 0\n",
    "            if isinstance(event, paddle.event.EndPass):\n",
    "                if test_off:\n",
    "                    print(\"\\n------- Time: %d sec,  Pass: %d\" %\n",
    "                          (time.time() - start_time, event.pass_id))\n",
    "                else:\n",
    "                    result = trainer.test(\n",
    "                        reader=adapted_dev_batch_reader,\n",
    "                        feeding=adapted_feeding_dict)\n",
    "                    print(\n",
    "                        \"\\n------- Time: %d sec,  Pass: %d, \"\n",
    "                        \"ValidationCost: %s\" %\n",
    "                        (time.time() - start_time, event.pass_id, result.cost))\n",
    "                output_model_path = os.path.join(\n",
    "                    output_model_dir, \"params.pass-%d.tar.gz\" % event.pass_id)\n",
    "                with gzip.open(output_model_path, 'w') as f:\n",
    "                    trainer.save_parameter_to_tar(f)\n",
    "\n",
    "        # run train\n",
    "        trainer.train(\n",
    "            reader=adapted_train_batch_reader,\n",
    "            event_handler=event_handler,\n",
    "            num_passes=num_passes,\n",
    "            feeding=adapted_feeding_dict)\n",
    "\n",
    "    # TODO(@pkuyym) merge this function into infer_batch\n",
    "    def infer_loss_batch(self, infer_data):\n",
    "        \"\"\"Model inference. Infer the ctc loss for a batch of speech\n",
    "        utterances.\n",
    "        :param infer_data: List of utterances to infer, with each utterance a\n",
    "                           tuple of audio features and transcription text (empty\n",
    "                           string).\n",
    "        :type infer_data: list\n",
    "        :return: List of ctc loss.\n",
    "        :rtype: List of float\n",
    "        \"\"\"\n",
    "        # define inferer\n",
    "        if self._loss_inferer == None:\n",
    "            self._loss_inferer = paddle.inference.Inference(\n",
    "                output_layer=self._loss, parameters=self._parameters)\n",
    "        # run inference\n",
    "        return self._loss_inferer.infer(input=infer_data)\n",
    "\n",
    "    def infer_batch_probs(self, infer_data, feeding_dict):\n",
    "        \"\"\"Infer the prob matrices for a batch of speech utterances.\n",
    "        :param infer_data: List of utterances to infer, with each utterance\n",
    "                           consisting of a tuple of audio features and\n",
    "                           transcription text (empty string).\n",
    "        :type infer_data: list\n",
    "        :param feeding_dict: Feeding is a map of field name and tuple index\n",
    "                             of the data that reader returns.\n",
    "        :type feeding_dict: dict|list\n",
    "        :return: List of 2-D probability matrix, and each consists of prob\n",
    "                 vectors for one speech utterancce.\n",
    "        :rtype: List of matrix\n",
    "        \"\"\"\n",
    "        # define inferer\n",
    "        if self._inferer == None:\n",
    "            self._inferer = paddle.inference.Inference(\n",
    "                output_layer=self._log_probs, parameters=self._parameters)\n",
    "        adapted_feeding_dict = self._adapt_feeding_dict(feeding_dict)\n",
    "        adapted_infer_data = self._adapt_data(infer_data)\n",
    "        # run inference\n",
    "        infer_results = self._inferer.infer(\n",
    "            input=adapted_infer_data, feeding=adapted_feeding_dict)\n",
    "        start_pos = [0] * (len(adapted_infer_data) + 1)\n",
    "        for i in xrange(len(adapted_infer_data)):\n",
    "            start_pos[i + 1] = start_pos[i] + adapted_infer_data[i][3][0]\n",
    "        probs_split = [\n",
    "            infer_results[start_pos[i]:start_pos[i + 1]]\n",
    "            for i in xrange(0, len(adapted_infer_data))\n",
    "        ]\n",
    "        return probs_split\n",
    "\n",
    "    def decode_batch_greedy(self, probs_split, vocab_list):\n",
    "        \"\"\"Decode by best path for a batch of probs matrix input.\n",
    "        :param probs_split: List of 2-D probability matrix, and each consists\n",
    "                            of prob vectors for one speech utterancce.\n",
    "        :param probs_split: List of matrix\n",
    "        :param vocab_list: List of tokens in the vocabulary, for decoding.\n",
    "        :type vocab_list: list\n",
    "        :return: List of transcription texts.\n",
    "        :rtype: List of basestring\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for i, probs in enumerate(probs_split):\n",
    "            output_transcription = ctc_greedy_decoder(\n",
    "                probs_seq=probs, vocabulary=vocab_list)\n",
    "            results.append(output_transcription)\n",
    "        return results\n",
    "\n",
    "    def init_ext_scorer(self, beam_alpha, beam_beta, language_model_path,\n",
    "                        vocab_list):\n",
    "        \"\"\"Initialize the external scorer.\n",
    "        :param beam_alpha: Parameter associated with language model.\n",
    "        :type beam_alpha: float\n",
    "        :param beam_beta: Parameter associated with word count.\n",
    "        :type beam_beta: float\n",
    "        :param language_model_path: Filepath for language model. If it is\n",
    "                                    empty, the external scorer will be set to\n",
    "                                    None, and the decoding method will be pure\n",
    "                                    beam search without scorer.\n",
    "        :type language_model_path: basestring|None\n",
    "        :param vocab_list: List of tokens in the vocabulary, for decoding.\n",
    "        :type vocab_list: list\n",
    "        \"\"\"\n",
    "        if language_model_path != '':\n",
    "            self.logger.info(\"begin to initialize the external scorer \"\n",
    "                             \"for decoding\")\n",
    "            self._ext_scorer = Scorer(beam_alpha, beam_beta,\n",
    "                                      language_model_path, vocab_list)\n",
    "            lm_char_based = self._ext_scorer.is_character_based()\n",
    "            lm_max_order = self._ext_scorer.get_max_order()\n",
    "            lm_dict_size = self._ext_scorer.get_dict_size()\n",
    "            self.logger.info(\"language model: \"\n",
    "                             \"is_character_based = %d,\" % lm_char_based +\n",
    "                             \" max_order = %d,\" % lm_max_order +\n",
    "                             \" dict_size = %d\" % lm_dict_size)\n",
    "            self.logger.info(\"end initializing scorer\")\n",
    "        else:\n",
    "            self._ext_scorer = None\n",
    "            self.logger.info(\"no language model provided, \"\n",
    "                             \"decoding by pure beam search without scorer.\")\n",
    "\n",
    "    def decode_batch_beam_search(self, probs_split, beam_alpha, beam_beta,\n",
    "                                 beam_size, cutoff_prob, cutoff_top_n,\n",
    "                                 vocab_list, num_processes):\n",
    "        \"\"\"Decode by beam search for a batch of probs matrix input.\n",
    "        :param probs_split: List of 2-D probability matrix, and each consists\n",
    "                            of prob vectors for one speech utterancce.\n",
    "        :param probs_split: List of matrix\n",
    "        :param beam_alpha: Parameter associated with language model.\n",
    "        :type beam_alpha: float\n",
    "        :param beam_beta: Parameter associated with word count.\n",
    "        :type beam_beta: float\n",
    "        :param beam_size: Width for Beam search.\n",
    "        :type beam_size: int\n",
    "        :param cutoff_prob: Cutoff probability in pruning,\n",
    "                            default 1.0, no pruning.\n",
    "        :type cutoff_prob: float\n",
    "        :param cutoff_top_n: Cutoff number in pruning, only top cutoff_top_n\n",
    "                        characters with highest probs in vocabulary will be\n",
    "                        used in beam search, default 40.\n",
    "        :type cutoff_top_n: int\n",
    "        :param vocab_list: List of tokens in the vocabulary, for decoding.\n",
    "        :type vocab_list: list\n",
    "        :param num_processes: Number of processes (CPU) for decoder.\n",
    "        :type num_processes: int\n",
    "        :return: List of transcription texts.\n",
    "        :rtype: List of basestring\n",
    "        \"\"\"\n",
    "        if self._ext_scorer != None:\n",
    "            self._ext_scorer.reset_params(beam_alpha, beam_beta)\n",
    "        # beam search decode\n",
    "        num_processes = min(num_processes, len(probs_split))\n",
    "        beam_search_results = ctc_beam_search_decoder_batch(\n",
    "            probs_split=probs_split,\n",
    "            vocabulary=vocab_list,\n",
    "            beam_size=beam_size,\n",
    "            num_processes=num_processes,\n",
    "            ext_scoring_func=self._ext_scorer,\n",
    "            cutoff_prob=cutoff_prob,\n",
    "            cutoff_top_n=cutoff_top_n)\n",
    "\n",
    "        results = [result[0][1] for result in beam_search_results]\n",
    "        return results\n",
    "\n",
    "    def _adapt_feeding_dict(self, feeding_dict):\n",
    "        \"\"\"Adapt feeding dict according to network struct.\n",
    "        To remove impacts from padding part, we add scale_sub_region layer and\n",
    "        sub_seq layer. For sub_seq layer, 'sequence_offset' and\n",
    "        'sequence_length' fields are appended. For each scale_sub_region layer\n",
    "        'convN_index_range' field is appended.\n",
    "        :param feeding_dict: Feeding is a map of field name and tuple index\n",
    "                             of the data that reader returns.\n",
    "        :type feeding_dict: dict|list\n",
    "        :return: Adapted feeding dict.\n",
    "        :rtype: dict|list\n",
    "        \"\"\"\n",
    "        adapted_feeding_dict = copy.deepcopy(feeding_dict)\n",
    "        if isinstance(feeding_dict, dict):\n",
    "            adapted_feeding_dict[\"sequence_offset\"] = len(adapted_feeding_dict)\n",
    "            adapted_feeding_dict[\"sequence_length\"] = len(adapted_feeding_dict)\n",
    "            for i in xrange(self._num_conv_layers):\n",
    "                adapted_feeding_dict[\"conv%d_index_range\" %i] = \\\n",
    "                        len(adapted_feeding_dict)\n",
    "        elif isinstance(feeding_dict, list):\n",
    "            adapted_feeding_dict.append(\"sequence_offset\")\n",
    "            adapted_feeding_dict.append(\"sequence_length\")\n",
    "            for i in xrange(self._num_conv_layers):\n",
    "                adapted_feeding_dict.append(\"conv%d_index_range\" % i)\n",
    "        else:\n",
    "            raise ValueError(\"Type of feeding_dict is %s, not supported.\" %\n",
    "                             type(feeding_dict))\n",
    "\n",
    "        return adapted_feeding_dict\n",
    "\n",
    "    def _adapt_data(self, data):\n",
    "        \"\"\"Adapt data according to network struct.\n",
    "        For each convolution layer in the conv_group, to remove impacts from\n",
    "        padding data, we can multiply zero to the padding part of the outputs\n",
    "        of each batch normalization layer. We add a scale_sub_region layer after\n",
    "        each batch normalization layer to reset the padding data.\n",
    "        For rnn layers, to remove impacts from padding data, we can truncate the\n",
    "        padding part before output data feeded into the first rnn layer. We use\n",
    "        sub_seq layer to achieve this.\n",
    "        :param data: Data from data_provider.\n",
    "        :type data: list|function\n",
    "        :return: Adapted data.\n",
    "        :rtype: list|function\n",
    "        \"\"\"\n",
    "\n",
    "        def adapt_instance(instance):\n",
    "            if len(instance) < 2 or len(instance) > 3:\n",
    "                raise ValueError(\"Size of instance should be 2 or 3.\")\n",
    "            padded_audio = instance[0]\n",
    "            text = instance[1]\n",
    "            # no padding part\n",
    "            if len(instance) == 2:\n",
    "                audio_len = padded_audio.shape[1]\n",
    "            else:\n",
    "                audio_len = instance[2]\n",
    "            adapted_instance = [padded_audio, text]\n",
    "            # Stride size for conv0 is (3, 2)\n",
    "            # Stride size for conv1 to convN is (1, 2)\n",
    "            # Same as the network, hard-coded here\n",
    "            padded_conv0_h = (padded_audio.shape[0] - 1) // 2 + 1\n",
    "            padded_conv0_w = (padded_audio.shape[1] - 1) // 3 + 1\n",
    "            valid_w = (audio_len - 1) // 3 + 1\n",
    "            adapted_instance += [\n",
    "                [0],  # sequence offset, always 0\n",
    "                [valid_w],  # valid sequence length\n",
    "                # Index ranges for channel, height and width\n",
    "                # Please refer scale_sub_region layer to see details\n",
    "                [1, 32, 1, padded_conv0_h, valid_w + 1, padded_conv0_w]\n",
    "            ]\n",
    "            pre_padded_h = padded_conv0_h\n",
    "            for i in xrange(self._num_conv_layers - 1):\n",
    "                padded_h = (pre_padded_h - 1) // 2 + 1\n",
    "                pre_padded_h = padded_h\n",
    "                adapted_instance += [\n",
    "                    [1, 32, 1, padded_h, valid_w + 1, padded_conv0_w]\n",
    "                ]\n",
    "            return adapted_instance\n",
    "\n",
    "        if isinstance(data, list):\n",
    "            return map(adapt_instance, data)\n",
    "        elif inspect.isgeneratorfunction(data):\n",
    "\n",
    "            def adapted_reader():\n",
    "                for instance in data():\n",
    "                    yield map(adapt_instance, instance)\n",
    "\n",
    "            return adapted_reader\n",
    "        else:\n",
    "            raise ValueError(\"Type of data is %s, not supported.\" % type(data))\n",
    "\n",
    "    def _create_parameters(self, model_path=None):\n",
    "        \"\"\"Load or create model parameters.\"\"\"\n",
    "        if model_path is None:\n",
    "            self._parameters = paddle.parameters.create(self._loss)\n",
    "        else:\n",
    "            self._parameters = paddle.parameters.Parameters.from_tar(\n",
    "                gzip.open(model_path))\n",
    "\n",
    "    def _create_network(self, vocab_size, num_conv_layers, num_rnn_layers,\n",
    "                        rnn_layer_size, use_gru, share_rnn_weights):\n",
    "        \"\"\"Create data layers and model network.\"\"\"\n",
    "        # paddle.data_type.dense_array is used for variable batch input.\n",
    "        # The size 161 * 161 is only an placeholder value and the real shape\n",
    "        # of input batch data will be induced during training.\n",
    "        audio_data = paddle.layer.data(\n",
    "            name=\"audio_spectrogram\",\n",
    "            type=paddle.data_type.dense_array(161 * 161))\n",
    "        text_data = paddle.layer.data(\n",
    "            name=\"transcript_text\",\n",
    "            type=paddle.data_type.integer_value_sequence(vocab_size))\n",
    "        seq_offset_data = paddle.layer.data(\n",
    "            name='sequence_offset',\n",
    "            type=paddle.data_type.integer_value_sequence(1))\n",
    "        seq_len_data = paddle.layer.data(\n",
    "            name='sequence_length',\n",
    "            type=paddle.data_type.integer_value_sequence(1))\n",
    "        index_range_datas = []\n",
    "        for i in xrange(num_rnn_layers):\n",
    "            index_range_datas.append(\n",
    "                paddle.layer.data(\n",
    "                    name='conv%d_index_range' % i,\n",
    "                    type=paddle.data_type.dense_vector(6)))\n",
    "\n",
    "        self._log_probs, self._loss = deep_speech_v2_network(\n",
    "            audio_data=audio_data,\n",
    "            text_data=text_data,\n",
    "            seq_offset_data=seq_offset_data,\n",
    "            seq_len_data=seq_len_data,\n",
    "            index_range_datas=index_range_datas,\n",
    "            dict_size=vocab_size,\n",
    "            num_conv_layers=num_conv_layers,\n",
    "            num_rnn_layers=num_rnn_layers,\n",
    "            rnn_size=rnn_layer_size,\n",
    "            use_gru=use_gru,\n",
    "            share_rnn_weights=share_rnn_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building a pretrained model with 10 second speech data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = DeepSpeech2Model(pretrained_model_path='baidu/models/parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = #input of 10 second speech data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flops = Interpret_Model(Model,inputs=())\n",
    "summary = print_summary(flops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
